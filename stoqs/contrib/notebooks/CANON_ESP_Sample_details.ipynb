{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze and Plot Details for LRAUV ESP Samples from CANON Campaigns\n",
    "*Query databases directly for detailed information that STOQS api requests don't deliver*\n",
    "\n",
    "Executing this Notebook requires a personal STOQS server.  It can be run from either a Docker installation or from a development Vagrant Virtual Machine. \n",
    "\n",
    "### Docker Instructions\n",
    "Install and start the software as \n",
    "[detailed in the README](https://github.com/stoqs/stoqs#production-deployment-with-docker). (Note that on MacOS you will need to modify settings in your `docker-compose.yml` and `.env` files &mdash; look for comments referencing 'HOST_UID'.)\n",
    "        \n",
    "Then, from your `$STOQS_HOME/docker` directory start the Jupyter Notebook server pointing to MBARI's master STOQS database server. Note: firewall rules limit unprivileged access to such resources.\n",
    "\n",
    "    docker-compose exec \\\n",
    "        -e DATABASE_URL=postgis://everyone:guest@kraken.shore.mbari.org:5432/stoqs \\\n",
    "        stoqs stoqs/manage.py shell_plus --notebook\n",
    "\n",
    "A message is displayed giving a URL for you to use in a browser on your host, e.g.:\n",
    "\n",
    "    http://127.0.0.1:8888/?token=<a_token_generated_upon_server_start>\n",
    "\n",
    "In the browser window opened to this URL navigate to this file (`stoqs/contrib/notebooks/CANON_ESP_Sample_details.ipynb`) and open it. You will then be able to execute the cells and modify the code to suit your needs.\n",
    "\n",
    "---\n",
    "\n",
    "### Vagrant VM Instructions\n",
    "Install and provision your VM as [detailed in the README](https://github.com/stoqs/stoqs#getting-started-with-a-stoqs-development-system) and configure to use MBARI's campaigns:\n",
    "\n",
    "    cd $STOQS_HOME/stoqs\n",
    "    ln -s mbari_campaigns.py campaigns.py\n",
    "\n",
    "Launch the Jupyter Notebook server on your VM using MBARI's master STOQS database server:\n",
    "\n",
    "    cd $STOQS_HOME/stoqs/contrib/notebooks\n",
    "    DATABASE_URL=postgis://everyone:guest@kraken.shore.mbari.org:5432/stoqs \\\n",
    "        ../../manage.py shell_plus --notebook\n",
    "        \n",
    "(Note: firewall rules limit unprivileged access to such resources.)\n",
    "\n",
    "A message is displayed giving a URL for you to use in a browser on your host, e.g.:\n",
    "\n",
    "    http://127.0.0.1:8888/?token=<a_token_generated_upon_server_start>\n",
    "\n",
    "Port 8888 on your Vagrant VM is mapped to port 8887 on your host, so in a web browser on your host open the URL (using the `<a_token_generated_upon_server_start>` printed after the Jupyter Notebook server is started):\n",
    "\n",
    "    http://127.0.0.1:8887/?token=<a_token_generated_upon_server_start>\n",
    "\n",
    "Navigate to this file (stoqs/contrib/notebooks/CANON_ESP_Sample_details.ipynb) and open it. You will then be able to execute the cells and modify the code to suit your needs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import ipywidgets as widgets\n",
    "from collections import OrderedDict\n",
    "\n",
    "# Prevent SynchronousOnlyOperation exceptions\n",
    "os.environ[\"DJANGO_ALLOW_ASYNC_UNSAFE\"] = \"true\"\n",
    "\n",
    "# Define Campaigns for which there are LRAUV ESP Samples\n",
    "dbs = OrderedDict([('CN17S', 'stoqs_canon_april2017'),\n",
    "                   ('CN18S', 'stoqs_canon_may2018'),\n",
    "                   ('CN18F', 'stoqs_canon_september2018'),\n",
    "                   ('CN19S', 'stoqs_canon_may2019'),\n",
    "                   ('CN19F', 'stoqs_canon_fall2019'),\n",
    "                   ('CN20S', 'stoqs_canon_july2020'),\n",
    "                   ('CN20F', 'stoqs_canon_october2020'),\n",
    "                 ])\n",
    "\n",
    "# Select Campaign using the Campaign ID key\n",
    "cid_picker = widgets.Dropdown(description='Campaign', options=dbs.keys(),\n",
    "                              layout={'width': 'max-content'})\n",
    "display(cid_picker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "# Save the ESP Sample identifers (Activity name) from each Campaign & list Campaign info\n",
    "cid_samples = defaultdict(list)\n",
    "for cid, db in dbs.items():\n",
    "    print(f\"{cid}: {db:25} - {Campaign.objects.using(db).get(id=1).description}\")\n",
    "    for sample in (Sample.objects.using(db)\n",
    "                   .filter(instantpoint__activity__platform__name__contains='ESP')\n",
    "                   .values_list('instantpoint__activity__name', flat=True)):\n",
    "        ##print(f\"\\t{sample}\")   # Uncomment to print all Samples - to check naming consistency\n",
    "        cid_samples[cid].append(sample)\n",
    "\n",
    "# Select Sample for analysis & plotting\n",
    "sample_picker = widgets.Dropdown(description=cid_picker.value,\n",
    "                                 options=cid_samples[cid_picker.value],\n",
    "                                 layout={'width': 'max-content'})\n",
    "display(sample_picker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from django.contrib.gis.geos import LineString\n",
    "\n",
    "def sample_details(cid, sample):\n",
    "    # Retrieve Sample details from STOQS database using Django's ORM & STOQS data model\n",
    "    # See: https://github.com/stoqs/stoqs/wiki/DatabaseSchema\n",
    "    locations = (Measurement.objects.using(dbs[cid])\n",
    "                            .filter(instantpoint__activity__name=sample)\n",
    "                            .order_by('instantpoint__timevalue'))\n",
    "    times = locations.values_list('instantpoint__timevalue', flat=True)\n",
    "    depths = locations.values_list('depth', flat=True)\n",
    "    track = LineString([p for p in locations.values_list('geom', flat=True)])    \n",
    "    return times, depths, track\n",
    "\n",
    "times, depths, track = sample_details(cid_picker.value, sample_picker.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipyleaflet import Map, Polyline, Marker\n",
    "\n",
    "# Plot the track taken during filtering\n",
    "line = Polyline(locations=[[point[1], point[0]] for point in track],\n",
    "                color=\"green\" ,\n",
    "                fill=False)\n",
    "m = Map(center=(track.centroid.y, track.centroid.x))\n",
    "m.add_layer(line)\n",
    "m.add_layer(Marker(location=(track.centroid.y, track.centroid.x), draggable=False, \n",
    "                   title=f\"{cid_picker.value} {sample_picker.value}\"))\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pylab as plt\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (15, 4)\n",
    "\n",
    "# Make plot of depth over time during filtering\n",
    "plt.gca().invert_yaxis()\n",
    "plt.plot(times, depths)\n",
    "plt.scatter(times[int(len(times)/2)], np.array(depths).mean(), color='k')\n",
    "plt.xlabel(f\"Time during {times[0].strftime('%d-%m-%Y')} (GMT)\")\n",
    "plt.ylabel(\"Depth (m)\")\n",
    "plt.title(f\"{cid_picker.value} {sample_picker.value}\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import lzstring\n",
    "\n",
    "# Create link to examine this Sample in the STOQS UI within the context of other campaign data\n",
    "depth_time = {'start-ems': times.first().timestamp()*1000,\n",
    "              'end-ems': times.last().timestamp()*1000,\n",
    "              'start-depth': min(depths),\n",
    "              'end-depth': max(depths)}\n",
    "compressor = lzstring.LZString()\n",
    "permalink = compressor.compressToEncodedURIComponent(json.dumps(depth_time, separators=(',', ':')))\n",
    "print(f\"https://stoqs.shore.mbari.org/{dbs[cid_picker.value]}/query/?permalink_id={permalink}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "# Find associated ESP.log file for the selected Sample\n",
    "log_act = Activity.objects.using(dbs[cid_picker.value]).get(name=sample_picker.value).comment.split()[-1]\n",
    "ar = ActivityResource.objects.using(dbs[cid_picker.value]).filter(activity__name=log_act,\n",
    "                                                                  resource__name='opendap_url')\n",
    "log_dir = '/'.join(ar[0].resource.value.split('/')[:-1])\n",
    "esp_log = f\"{log_dir}/ESP.log\"\n",
    "\n",
    "# Read from the ESP.log\n",
    "# TODO: Parse the information here and marry it with data from STOQS for more plots\n",
    "resp = requests.get(esp_log)\n",
    "for line in resp.iter_lines():\n",
    "    print(line.decode())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is optional code for looping through all Samples from all Campaigns. This can be a starting point for a standalone script (not a Jupyter Notebook) for performing bulk analysis and plot creation for a whole set of Samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.utils import percentile, median, mode\n",
    "\n",
    "# Example code to loop through all the Samples\n",
    "# May overwhelm the Notebook if break statements removed !\n",
    "for cid, samples in cid_samples.items():\n",
    "    print(f\"{cid}\")\n",
    "    for sample in samples:        \n",
    "        times, depth_list, track = sample_details(cid, sample)\n",
    "        print(f\"\\t{sample}: number of measurements = {len(times)}\")\n",
    "        lons = np.array([x for x, y in track])\n",
    "        lats = np.array([y for x, y in track])\n",
    "        depths = np.array(depth_list)\n",
    "\n",
    "        print(f\"\\tlon min    = {lons.min():.7f}\")\n",
    "        print(f\"\\tlon mean   = {lons.mean():.7f}\")\n",
    "        print(f\"\\tlon median = {median(list(lons)):.7f}\")\n",
    "        print(f\"\\tlon mode   = {mode(lons):.7f}\")\n",
    "        print(f\"\\tlon max    = {lons.max():.7f}\")\n",
    "        \n",
    "        print(f\"\\tlat min    = {lats.min():.7f}\")\n",
    "        print(f\"\\tlat mean   = {lats.mean():.7f}\")\n",
    "        print(f\"\\tlat median = {median(list(lats)):.7f}\")\n",
    "        print(f\"\\tlat mode   = {mode(lats):.7f}\")\n",
    "        print(f\"\\tlat max    = {lats.max():.7f}\")\n",
    "        \n",
    "        print(f\"\\tdepth min    = {depths.min():.2f}\")\n",
    "        print(f\"\\tdepth mean   = {depths.mean():.2f}\")\n",
    "        print(f\"\\tdepth median = {median(list(depths)):.2f}\")\n",
    "        print(f\"\\tdepth mode   = {mode(depths):.2f}\")\n",
    "        print(f\"\\tdepth max    = {depths.max():.2f}\")\n",
    "        break\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Django Shell-Plus",
   "language": "python",
   "name": "django_extensions"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
